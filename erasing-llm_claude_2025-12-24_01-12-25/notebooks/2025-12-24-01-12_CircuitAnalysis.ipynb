{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418ebbe7",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/smallyan/eval_agent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/smallyan/eval_agent')\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d7bfab",
   "metadata": {},
   "source": [
    "# Circuit Analysis Code Evaluation\n",
    "\n",
    "This notebook evaluates the code implementation under `/net/scratch2/smallyan/erasing-llm_eval` for circuit analysis.\n",
    "\n",
    "## Setup and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b2e206",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erasing-llm_eval/\n",
      "  documentation.pdf\n",
      "  .gitignore\n",
      "  __init__.py\n",
      "  CodeWalkthrough.md\n",
      "  requirements.txt\n",
      "  plan.md\n",
      "  trainscripts/\n",
      "    erase.py\n",
      "    prepare_consistency_data.py\n",
      "    __init__.py\n",
      "  utils/\n",
      "    metrics.py\n",
      "    __init__.py\n",
      "    lora.py\n",
      "  data/\n",
      "    wmdp-keywords.json\n",
      "    harrypotter/\n",
      "      hp-questions-dual.json\n",
      "      hp-questions.json\n",
      "    wmdp/\n",
      "      bio-questions.json\n",
      "      chem-questions.json\n",
      "      cyber-questions.json\n",
      "  notebooks/\n",
      "    inference.ipynb\n",
      "  images/\n",
      "    method.png\n",
      "  evaluation/\n",
      "    generalization_eval_summary.json\n",
      "    self_matching.ipynb\n",
      "    generalization_eval.ipynb\n",
      "    consistency_evaluation.json\n",
      "    replications/\n",
      "      evaluation_replication.md\n",
      "      self_replication_evaluation.json\n",
      "      documentation_replication.md\n",
      "      training_losses.png\n",
      "      replication.ipynb\n",
      "      elm_model/\n",
      "        adapter_config.json\n",
      "        adapter_model.safetensors\n",
      "        README.md\n",
      "    replication_eval/\n",
      "      documentation_eval_summary.json\n",
      "      documentation_evaluation_summary.md\n"
     ]
    }
   ],
   "source": [
    "# First, let's explore the repository structure\n",
    "REPO_PATH = \"/net/scratch2/smallyan/erasing-llm_eval\"\n",
    "\n",
    "# List all files in the repository\n",
    "for root, dirs, files in os.walk(REPO_PATH):\n",
    "    # Skip hidden directories and common non-essential directories\n",
    "    dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'venv', '.git']]\n",
    "    level = root.replace(REPO_PATH, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        print(f'{subindent}{file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5842f5e",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "Based on the Plan and CodeWalkthrough files:\n",
    "\n",
    "**Project Goal**: Erasure of Language Memory (ELM) - a method for erasing conceptual knowledge from language models by:\n",
    "1. Using introspective classification with expert/novice context prompts\n",
    "2. Three loss terms: Lerase, Lretain, and Lfluency\n",
    "3. Low-rank adapters (LoRA) applied to early model layers\n",
    "\n",
    "**Core Analysis Files to Evaluate**:\n",
    "1. `trainscripts/erase.py` - Main training script\n",
    "2. `trainscripts/prepare_consistency_data.py` - Pre-generating consistency data\n",
    "3. `utils/metrics.py` - Metrics utilities\n",
    "4. `utils/lora.py` - LoRA utilities\n",
    "5. `notebooks/inference.ipynb` - Testing notebook\n",
    "6. `evaluation/` - Evaluation notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a9081",
   "metadata": {},
   "source": [
    "## Files to Evaluate\n",
    "\n",
    "Based on the CodeWalkthrough.md and plan.md, the core analysis files are:\n",
    "\n",
    "### Python Modules (trainscripts/)\n",
    "1. `trainscripts/erase.py` - Main ELM training script\n",
    "2. `trainscripts/prepare_consistency_data.py` - Data preparation for consistency training\n",
    "\n",
    "### Utility Modules (utils/)\n",
    "3. `utils/metrics.py` - Evaluation metrics (WMDP, MMLU, HP accuracy)\n",
    "4. `utils/lora.py` - LoRA network implementation\n",
    "\n",
    "### Notebooks\n",
    "5. `notebooks/inference.ipynb` - Model inference and testing\n",
    "\n",
    "### Key Functions to Evaluate in erase.py:\n",
    "- `get_edit_vector()` - Computes ELM edit vector\n",
    "- `ELMLogits` class - Custom logits processor\n",
    "- `generate()` - Text generation with ELM guidance\n",
    "- `prepare_prompts()` - Dataset preparation\n",
    "- `train_elm()` - Main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a2f509",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: NVIDIA A100 80GB PCIe\n",
      "Device count: 1\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "    \n",
    "# Set device\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scribe: 2025-12-24-01-12_CircuitAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
